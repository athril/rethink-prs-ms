## Results

### Generation of synthetic datasets

First and foremost, it needs to be acknowledged how much effort was made in order to complete the generation of the datasets for running the actual experiment. In order to generate each of 450 datasets, corresponding to pairwise comparisons between 10 ML methods, HIBACHI had to run for 50 iterations with 500 individuals. At each of 50 iterations, 2 ML methods were evaluated across 500 different potential solutions to the problem using 5 different sets of hyperparameters. This means that over 112M of evaluations of a ML method were made in order to make the further comparison objective. As the number of potential hyperparameters differed depending on the method (so as the number of values), the methods that had the largest space had better chances to outperform the others. The statistics showing how often a given ML method outperformed the other is presented in Figure {@fig:classcomp}.

![The frequency of "up" ML method outperforming "down" method (ideally all the chart should be red)](images/class_comp.eps){#fig:classcomp width="70%"}


In the majority of the scenarios, the ML method that was handicaped won against its competetitors in the vast majority of the scenarios. It may be noticed however that two ML methods performed visibly better than the others, namely GradientBoosting following by XGBoost. The methods, even run as "down" scenarios, still managed to obtain the higher accuracy in comparison to the handicapped "up" method. There are two potential explanations for it. First, those two ML methods are known for their stellar performance on different sets of problems and are considered one of the leading supervised ML methods. Secondly, the size of the grid of their hyperparameters was the broadest. This may suggest that random selection of the values of the parameters within the large grid allows the method to find more accurate solutions.



### MRS outperforms standard PRS in the majority of simulated datasets

In 335 out of 450 simulated datasets, MRS produces higher auROC compared to PRS (green lines, Fig. {@fig:auroc_mrs_prs}).
In 363 datasets where the standard PRS method performs poorly (auROC < 60%), MRS performs particularly well (auROC > 90%) in 102 datasets.
When MRS yields smaller auROC, the difference is small (3.3% Â± 2.8%, purple lines/areas).
Across all datasets, the improvement of MRS over PRS is significant (P < $10^{-15}$) according to a Wilcoxon signed rank test.
To assess whether this improvement in performance correlates with the number of interaction effects contained in each dataset, in the following section, we untangled the two components of MRS and test for the correlation between the difference in auROC and two entropy-based measures, main and interaction effect, of each dataset.

![MRS produces improved auROC in the majority (335 green lines) of the 450 simulated datasets (each line represents a dataset). In many datasets, the standard PRS method performs poorly (auROC < 60%) while the new method yields auROC over 90%. This improvement in performance can be seen at the second peak (~50% auROC increase) in the density of the difference between the auROCs from the two methods (right).](images/1_ori_vs_MRS_auROC_.svg){#fig:auroc_mrs_prs width="80%"}

### Assess improvement in performance
Individually, MRS1 and MRS2 both significantly outperformed the standard PRS method (both P values < $10^{-15}$) according to a Wilcoxon signed rank test.
As the amount of main effects increases (Fig. {@fig:improvements} left column), MRS1 increasingly performs better than PRS, which is likely because encodings are inferred (top left).
Meanwhile, MRS2's accuracy remain mostly similar to that of PRS (middle left).
On the other hand, when the amount of interaction effects increases (Fig. {@fig:improvements} right column), MRS1 performs mostly on par to PRS while MRS2 increasingly performs better than PRS.
Combining the gain from both MRS1 and MRS2, MRS's performance progressively increases compared to the standard PRS.

![Combining 1-way (MRS1) and 2-way (MRS2) risk scores, MRS shows increasing outperformance to standard PRS as dataset contains more main and interaction effects.](images/improvements_train_ms.svg){#fig:improvements width="70%"}
